{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pynq_dpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c007e0efe1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpynq_dpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpynq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pynq_dpu'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import platform\n",
    "import tqdm\n",
    "from typing import Tuple, List, Union, Any\n",
    "import pynq_dpu\n",
    "import pynq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Dane ewaluacyjne\n",
    "Definicja danych i dataloaderÃ³w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalLoader:\n",
    "    def __init__(self, \n",
    "                 batch_size: int = 1, \n",
    "                 npz_path: str = 'eval_PST900.npz') -> None:\n",
    "        data = np.load(npz_path)\n",
    "        self.data = data['data'].astype(np.float32)\n",
    "        self.targets = data['targets']\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i >= len(self):\n",
    "            raise StopIteration\n",
    "\n",
    "        beg = min(i * self.batch_size, self.data.shape[0])\n",
    "        end = min(beg + self.batch_size, self.data.shape[0])\n",
    "\n",
    "        return self.data[beg:end, ...], self.targets[beg:end]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] // self.batch_size\n",
    "\n",
    "\n",
    "class TimeMeasurement:\n",
    "    def __init__(self, context_name: str, frames: int) -> None:\n",
    "        self.context_name: str = context_name\n",
    "        self.frames: int = frames\n",
    "        self.begin: float = None\n",
    "        self.end: float = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.begin = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "\n",
    "    @property\n",
    "    def time(self) -> float:\n",
    "        if self.begin is None or self.end is None:\n",
    "            raise RuntimeError()\n",
    "        return int(self.end - self.begin)\n",
    "\n",
    "    @property\n",
    "    def fps(self):\n",
    "        return self.frames / self.time\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = int(t - h*60 - min*60)\n",
    "        ms = int((t - np.floor(t))*1000)\n",
    "\n",
    "        return f\"Execution time: {h}:{min}:{s}:{ms}, processed {self.frames} frames, throughput: {self.fps} fps.\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = np.floor(t - h*60 - min*60)\n",
    "        ms = np.floor((t - np.floor(t))*1000)\n",
    "\n",
    "        return f'TimeMeasurement(context=\"{self.context_name}\",\"{h}:{min}:{s}:{ms}\", frames={self.frames}, throughput={self.fps})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definicja modelu sieci na DPU\n",
    "Inicjalizacja mierzenia czasu, funkcji softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray, axis=1):\n",
    "    x = np.exp(x)\n",
    "    x = x / np.sum(x, axis=axis)\n",
    "    return x\n",
    "\n",
    "class NetworkDPU:\n",
    "    \n",
    "    def __init__(self, xmodel_path: str = 'Darknet.xmodel', dpu_path: str = 'dpu.bit'):\n",
    "        self.ov: pynq_dpu.DpuOverlay = pynq_dpu.DpuOverlay(dpu_path, download=True)\n",
    "        self.ov.load_model(xmodel_path)\n",
    "        self.dpu = self.ov.runner\n",
    "        print(self.ov.runner)\n",
    "        inputTensors = self.dpu.get_input_tensors()\n",
    "        outputTensors = self.dpu.get_output_tensors()\n",
    "        # get list of shapes\n",
    "        shapeIn = np.array([it.dims for it in inputTensors])\n",
    "        shapeOut = np.array([ot.dims for ot in outputTensors])\n",
    "        self.shapeIn = shapeIn\n",
    "        self.shapeOut = shapeOut\n",
    "        self.buff_in = [np.zeros(sh, np.int8, order='C') for sh in shapeIn]\n",
    "        self.buff_out = [np.zeros(sh, np.int8, order='C') for sh in shapeOut]\n",
    "        \n",
    "        self.input_repr = [(it.get_attr('bit_width'), it.get_attr('fix_point')) for it in inputTensors]\n",
    "        self.output_repr = [(ot.get_attr('bit_width'), ot.get_attr('fix_point')) for ot in outputTensors]\n",
    "    \n",
    "    def input_float_to_int8(self, x: np.ndarray) -> np.ndarray:\n",
    "        BIT_WIDTH, PRECISION_BITS = self.input_repr[0]\n",
    "        x = x * (2**PRECISION_BITS)\n",
    "        x = np.floor(x)\n",
    "        x = np.clip(x,-128, 127)\n",
    "        return x.astype(np.int8)\n",
    "    \n",
    "    def output_int8_to_float(self, y: np.ndarray):\n",
    "        BIT_WIDTH, PRECISION_BITS = self.output_repr[0]\n",
    "        PRECISION = 1 / 2**PRECISION_BITS\n",
    "        y = y * PRECISION\n",
    "        return y.astype(np.float32)\n",
    "    \n",
    "    def process(self, x: np.ndarray):\n",
    "        x = self.input_float_to_int8(x)\n",
    "        self.buff_in[0] = x\n",
    "        # start DPU thread\n",
    "        job_id = self.dpu.execute_async(self.buff_in, self.buff_out)\n",
    "        self.dpu.wait(job_id)\n",
    "        y = self.buff_out[0]\n",
    "        y = self.output_int8_to_float(y)\n",
    "        y = softmax(y)\n",
    "        return y\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> Any:\n",
    "        return self.process(x)\n",
    "    \n",
    "def bbox_iou_numpy(box1, box2):\n",
    "    \"\"\"Computes IoU between bounding boxes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    box1 : ndarray\n",
    "        (N, 4) shaped array with bboxes\n",
    "    box2 : ndarray\n",
    "        (M, 4) shaped array with bboxes\n",
    "    Returns\n",
    "    -------\n",
    "    : ndarray\n",
    "        (N, M) shaped array with IoUs\n",
    "    \"\"\"\n",
    "    area = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "\n",
    "    iw = np.minimum(np.expand_dims(box1[:, 2], axis=1), box2[:, 2]) - np.maximum(\n",
    "        np.expand_dims(box1[:, 0], 1), box2[:, 0]\n",
    "    )\n",
    "    ih = np.minimum(np.expand_dims(box1[:, 3], axis=1), box2[:, 3]) - np.maximum(\n",
    "        np.expand_dims(box1[:, 1], 1), box2[:, 1]\n",
    "    )\n",
    "\n",
    "    iw = np.maximum(iw, 0)\n",
    "    ih = np.maximum(ih, 0)\n",
    "\n",
    "    ua = np.expand_dims((box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1]), axis=1) + area - iw * ih\n",
    "\n",
    "    ua = np.maximum(ua, np.finfo(float).eps)\n",
    "\n",
    "    intersection = iw * ih\n",
    "\n",
    "    return intersection / ua\n",
    "\n",
    "\n",
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precision, [0.0]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inicjalizacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = EvalLoader()\n",
    "tm = TimeMeasurement(\"Evaluation on KV260\", loader.batch_size * len(loader))\n",
    "\n",
    "net = NetworkDPU(xmodel_path='Darknet_qu.xmodel', \n",
    "                 dpu_path='dpu.bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Definicja funkcji do ewaluacji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: NetworkDPU,\n",
    "               data_loader: EvalLoader,\n",
    "               ) -> Tuple[float, float]:\n",
    "\n",
    "    print(f\"Running on platform: {platform.platform()}, \"\n",
    "          f\"machine: {platform.machine()}, \"\n",
    "          f\"python_version: {platform.python_version()}, \"\n",
    "          f\"processor: {platform.processor()}, \"\n",
    "          f\"system: {platform.system()}, \"\n",
    "          )\n",
    "    \n",
    "    # for i, (X, y_ref) in tqdm.tqdm(enumerate(data_loader),):\n",
    "    #     y_pred = model(X)\n",
    "        \n",
    "    #     # calculate loss\n",
    "    #     loss = criterion(y_pred, y_ref)\n",
    "        \n",
    "    #     # calculate accuracy\n",
    "    #     accuracy = metric(y_pred, y_ref)\n",
    "\n",
    "    #     total_loss += loss * y_pred.shape[0]\n",
    "    #     total_accuracy += accuracy * y_pred.shape[0]\n",
    "    #     samples_num += y_pred.shape[0]\n",
    "\n",
    "    num_classes = 4\n",
    "    img_size = 416\n",
    "    iou_thres = 0.5\n",
    "\n",
    "    all_detections = []\n",
    "    all_annotations = []\n",
    "\n",
    "    for batch_i, (imgs, targets) in enumerate(tqdm.tqdm(data_loader, desc=\"Detecting objects\")):\n",
    "\n",
    "        # imgs = Variable(imgs.type(Tensor))\n",
    "        # targets = Variable(targets.type(Tensor), requires_grad=False)\n",
    "\n",
    "\n",
    "        # img = imgs[0].cpu().numpy()\n",
    "        # img = img[:3] * 255\n",
    "        # img = np.transpose(img, (1, 2, 0)).astype(np.uint8)\n",
    "\n",
    "        # target = targets[0].cpu().numpy()\n",
    "\n",
    "        # print(type(img), img.shape, img.dtype)\n",
    "        # for t in target:\n",
    "        #     cls, x, y, w, h = t\n",
    "\n",
    "        #     if x != 0 and y != 0 and w != 0 and h != 0:\n",
    "        #         cx = int(x * 416)\n",
    "        #         cy = int(y * 416)\n",
    "        #         w = int(w * 416)\n",
    "        #         h = int(h * 416)\n",
    "\n",
    "        #         x = cx - w // 2\n",
    "        #         y = cy - h // 2\n",
    "\n",
    "        #         img = np.ascontiguousarray(img)\n",
    "\n",
    "        #         img = cv.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        #         cv.imshow(\"img\", img)\n",
    "        #         cv.waitKey(0)\n",
    "\n",
    "\n",
    "        outputs = model(imgs)        \n",
    "\n",
    "        for output, annotations in zip(outputs, targets):\n",
    "\n",
    "            all_detections.append([np.array([]) for _ in range(num_classes)])\n",
    "            if output is not None:\n",
    "                # Get predicted boxes, confidence scores and labels\n",
    "                pred_boxes = output[:, :5].cpu().numpy()\n",
    "                scores = output[:, 4].cpu().numpy()\n",
    "                pred_labels = output[:, -1].cpu().numpy()\n",
    "\n",
    "                # Order by confidence\n",
    "                sort_i = np.argsort(scores)\n",
    "                pred_labels = pred_labels[sort_i]\n",
    "                pred_boxes = pred_boxes[sort_i]\n",
    "                \n",
    "                print(\"Batch:\", batch_i)\n",
    "                print(\"pred_boxes:\", pred_boxes)\n",
    "                print(\"scores:\", scores)\n",
    "                print(\"pred_labels:\", pred_labels)\n",
    "\n",
    "                for label in range(num_classes):\n",
    "                    all_detections[-1][label] = pred_boxes[pred_labels == label]\n",
    "\n",
    "            all_annotations.append([np.array([]) for _ in range(num_classes)])\n",
    "            if any(annotations[:, -1] > 0):\n",
    "\n",
    "                annotation_labels = annotations[annotations[:, -1] > 0, 0].cpu().numpy()\n",
    "                _annotation_boxes = annotations[annotations[:, -1] > 0, 1:].cpu()\n",
    "\n",
    "                # Reformat to x1, y1, x2, y2 and rescale to image dimensions\n",
    "                annotation_boxes = np.empty_like(_annotation_boxes)\n",
    "                annotation_boxes[:, 0] = _annotation_boxes[:, 0] - _annotation_boxes[:, 2] / 2\n",
    "                annotation_boxes[:, 1] = _annotation_boxes[:, 1] - _annotation_boxes[:, 3] / 2\n",
    "                annotation_boxes[:, 2] = _annotation_boxes[:, 0] + _annotation_boxes[:, 2] / 2\n",
    "                annotation_boxes[:, 3] = _annotation_boxes[:, 1] + _annotation_boxes[:, 3] / 2\n",
    "                annotation_boxes *= img_size\n",
    "\n",
    "                for label in range(num_classes):\n",
    "                    all_annotations[-1][label] = annotation_boxes[annotation_labels == label, :]\n",
    "\n",
    "    average_precisions = {}\n",
    "    for label in range(num_classes):\n",
    "        true_positives = []\n",
    "        scores = []\n",
    "        num_annotations = 0\n",
    "\n",
    "        for i in tqdm.tqdm(range(len(all_annotations)), desc=f\"Computing AP for class '{label}'\"):\n",
    "            detections = all_detections[i][label]\n",
    "            annotations = all_annotations[i][label]\n",
    "\n",
    "            num_annotations += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            for *bbox, score in detections:\n",
    "                scores.append(score)\n",
    "\n",
    "                if annotations.shape[0] == 0:\n",
    "                    true_positives.append(0)\n",
    "                    continue\n",
    "\n",
    "                overlaps = bbox_iou_numpy(np.expand_dims(bbox, axis=0), annotations)\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "                if max_overlap >= iou_thres and assigned_annotation not in detected_annotations:\n",
    "                    true_positives.append(1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    true_positives.append(0)\n",
    "\n",
    "        # no annotations -> AP for this class is 0\n",
    "        if num_annotations == 0:\n",
    "            average_precisions[label] = 0\n",
    "            continue\n",
    "\n",
    "        true_positives = np.array(true_positives)\n",
    "        false_positives = np.ones_like(true_positives) - true_positives\n",
    "        # sort by score\n",
    "        indices = np.argsort(-np.array(scores))\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision = compute_ap(recall, precision)\n",
    "        average_precisions[label] = average_precision\n",
    "\n",
    "    logger = {}\n",
    "    print(\"Average Precisions:\")\n",
    "    for c, ap in average_precisions.items():\n",
    "        print(f\"+ Class '{c}' - AP: {ap}\")\n",
    "        logger[c] = ap\n",
    "\n",
    "    mAP = np.mean(list(average_precisions.values()))\n",
    "    logger[\"mAP\"] = mAP\n",
    "    print(f\"mAP: {mAP}\")\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicjalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tm:\n",
    "    evaluation(net, loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
