{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494f9aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import platform\n",
    "import tqdm\n",
    "from typing import Tuple, Any\n",
    "import pynq_dpu\n",
    "import pynq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39017d6b",
   "metadata": {},
   "source": [
    "### 1. The eval data\n",
    "Define data and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f23e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalLoader:\n",
    "    def __init__(self, \n",
    "                 batch_size: int = 1, \n",
    "                 npz_path: str = 'eval_PST900.npz') -> None:\n",
    "        data = np.load(npz_path)\n",
    "        self.data = data['data'].astype(np.float32)\n",
    "        self.targets = data['targets']\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i >= len(self):\n",
    "            raise StopIteration\n",
    "\n",
    "        beg = min(i * self.batch_size, self.data.shape[0])\n",
    "        end = min(beg + self.batch_size, self.data.shape[0])\n",
    "\n",
    "        return self.data[beg:end, ...], self.targets[beg:end]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] // self.batch_size\n",
    "\n",
    "\n",
    "class TimeMeasurement:\n",
    "    def __init__(self, context_name: str, frames: int) -> None:\n",
    "        self.context_name: str = context_name\n",
    "        self.frames: int = frames\n",
    "        self.begin: float = None\n",
    "        self.end: float = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.begin = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "\n",
    "    @property\n",
    "    def time(self) -> float:\n",
    "        if self.begin is None or self.end is None:\n",
    "            raise RuntimeError()\n",
    "        return int(self.end - self.begin)\n",
    "\n",
    "    @property\n",
    "    def fps(self):\n",
    "        return self.frames / self.time\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = int(t - h*60 - min*60)\n",
    "        ms = int((t - np.floor(t))*1000)\n",
    "\n",
    "        return f\"Execution time: {h}:{min}:{s}:{ms}, processed {self.frames} frames, throughput: {self.fps} fps.\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = np.floor(t - h*60 - min*60)\n",
    "        ms = np.floor((t - np.floor(t))*1000)\n",
    "\n",
    "        return f'TimeMeasurement(context=\"{self.context_name}\",\"{h}:{min}:{s}:{ms}\", frames={self.frames}, throughput={self.fps})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866c03e",
   "metadata": {},
   "source": [
    "### 2. Net definition on DPU\n",
    "Add required functions (softmax, bbox, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fef8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray, axis=1):\n",
    "    x = np.exp(x)\n",
    "    x = x / np.sum(x, axis=axis)\n",
    "    return x\n",
    "\n",
    "class NetworkDPU:\n",
    "    \n",
    "    def __init__(self, xmodel_path: str = 'Darknet.xmodel', dpu_path: str = 'dpu.bit'):\n",
    "        self.ov: pynq_dpu.DpuOverlay = pynq_dpu.DpuOverlay(dpu_path, download=True)\n",
    "        self.ov.load_model(xmodel_path)\n",
    "        self.dpu = self.ov.runner\n",
    "        print(self.ov.runner)\n",
    "        inputTensors = self.dpu.get_input_tensors()\n",
    "        outputTensors = self.dpu.get_output_tensors()\n",
    "        # get list of shapes\n",
    "        shapeIn = np.array([it.dims for it in inputTensors])\n",
    "        print(shapeIn)\n",
    "        shapeOut = np.array([ot.dims for ot in outputTensors])\n",
    "        print(shapeOut)\n",
    "        self.shapeIn = shapeIn\n",
    "        self.shapeOut = shapeOut\n",
    "        self.buff_in = [np.zeros(sh, np.int8, order='C') for sh in shapeIn]\n",
    "        self.buff_out = [np.zeros(sh, np.int8, order='C') for sh in shapeOut]\n",
    "        \n",
    "        self.input_repr = [(it.get_attr('bit_width'), it.get_attr('fix_point')) for it in inputTensors]\n",
    "        self.output_repr = [(ot.get_attr('bit_width'), ot.get_attr('fix_point')) for ot in outputTensors]\n",
    "    \n",
    "    def input_float_to_int8(self, x: np.ndarray) -> np.ndarray:\n",
    "        BIT_WIDTH, PRECISION_BITS = self.input_repr[0]\n",
    "        x = x * (2**PRECISION_BITS)\n",
    "        x = np.floor(x)\n",
    "        x = np.clip(x,-128, 127)\n",
    "        return x.astype(np.int8)\n",
    "    \n",
    "    def output_int8_to_float(self, y: np.ndarray):\n",
    "        BIT_WIDTH, PRECISION_BITS = self.output_repr[0]\n",
    "        PRECISION = 1 / 2**PRECISION_BITS\n",
    "        y = y * PRECISION\n",
    "        return y.astype(np.float32)\n",
    "    \n",
    "    def process(self, x: np.ndarray):\n",
    "        x = self.input_float_to_int8(x)\n",
    "        self.buff_in[0] = x\n",
    "        # start DPU thread\n",
    "        job_id = self.dpu.execute_async(self.buff_in, self.buff_out)\n",
    "        self.dpu.wait(job_id)\n",
    "        y = self.buff_out[0]\n",
    "        y = self.output_int8_to_float(y)\n",
    "        y = softmax(y)\n",
    "        y1 = self.buff_out[1]\n",
    "        y1 = self.output_int8_to_float(y1)\n",
    "        y1 = softmax(y1)\n",
    "        y2 = self.buff_out[2]\n",
    "        y2 = self.output_int8_to_float(y2)\n",
    "        y2 = softmax(y2)\n",
    "        return y, y1, y2\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> Any:\n",
    "        return self.process(x)\n",
    "    \n",
    "def bbox_iou_numpy(box1, box2):\n",
    "    \"\"\"Computes IoU between bounding boxes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    box1 : ndarray\n",
    "        (N, 4) shaped array with bboxes\n",
    "    box2 : ndarray\n",
    "        (M, 4) shaped array with bboxes\n",
    "    Returns\n",
    "    -------\n",
    "    : ndarray\n",
    "        (N, M) shaped array with IoUs\n",
    "    \"\"\"\n",
    "    area = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "\n",
    "    iw = np.minimum(np.expand_dims(box1[:, 2], axis=1), box2[:, 2]) - np.maximum(\n",
    "        np.expand_dims(box1[:, 0], 1), box2[:, 0]\n",
    "    )\n",
    "    ih = np.minimum(np.expand_dims(box1[:, 3], axis=1), box2[:, 3]) - np.maximum(\n",
    "        np.expand_dims(box1[:, 1], 1), box2[:, 1]\n",
    "    )\n",
    "\n",
    "    iw = np.maximum(iw, 0)\n",
    "    ih = np.maximum(ih, 0)\n",
    "\n",
    "    ua = np.expand_dims((box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1]), axis=1) + area - iw * ih\n",
    "\n",
    "    ua = np.maximum(ua, np.finfo(float).eps)\n",
    "\n",
    "    intersection = iw * ih\n",
    "\n",
    "    return intersection / ua\n",
    "\n",
    "\n",
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precision, [0.0]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3337a9",
   "metadata": {},
   "source": [
    "### 3. Net init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c33c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = EvalLoader()\n",
    "tm = TimeMeasurement(\"Evaluation on KV260\", loader.batch_size * len(loader))\n",
    "\n",
    "net = NetworkDPU(xmodel_path='Darknet_qu_0_15mAP.xmodel', \n",
    "                 dpu_path='dpu.bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_i, (imgs, targets) in enumerate(loader):\n",
    "    print(\"Batch:\", batch_i)\n",
    "    print(\"Img:\",imgs.shape)\n",
    "    print(\"Target:\",targets.shape)\n",
    "    img = imgs\n",
    "    target = targets\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b22cb7f",
   "metadata": {},
   "source": [
    "Calculate a time of processing through net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32287a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = time.time()\n",
    "for _, (img, target) in enumerate(loader):\n",
    "    o1, o2, o3 = net(imgs)\n",
    "etime = time.time() - stime\n",
    "print(etime)\n",
    "print(etime / len(loader))\n",
    "print(o1.shape)\n",
    "print(o2.shape)\n",
    "print(o3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe1f89",
   "metadata": {},
   "source": [
    "Definie YOLO Layer to add it at the end of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d3336bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOLayer(nn.Module):\n",
    "    \"\"\"Detection layer\"\"\"\n",
    "\n",
    "    def __init__(self, anchors, num_classes, img_dim):\n",
    "        super(YOLOLayer, self).__init__()\n",
    "        self.anchors = anchors\n",
    "        self.anchors_tensor = torch.tensor(self.anchors)\n",
    "        self.num_anchors = len(anchors)\n",
    "        self.num_classes = num_classes\n",
    "        self.bbox_attrs = 5 + num_classes\n",
    "        self.image_dim = img_dim\n",
    "        self.ignore_thres = 0.5\n",
    "        self.lambda_coord = 1\n",
    "\n",
    "        self.mse_loss = nn.MSELoss(size_average=True)  # Coordinate loss\n",
    "        self.bce_loss = nn.BCELoss(size_average=True)  # Confidence loss\n",
    "        self.ce_loss = nn.CrossEntropyLoss()  # Class loss\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        x = torch.from_numpy(x)\n",
    "        nA = self.num_anchors\n",
    "        nB = x.size(0)\n",
    "        nG = x.size(2)\n",
    "        stride = self.image_dim / nG\n",
    "\n",
    "        # Tensors for cuda support\n",
    "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
    "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
    "        ByteTensor = torch.cuda.ByteTensor if x.is_cuda else torch.ByteTensor\n",
    "        Tensor = torch.cuda.Tensor if x.is_cuda else torch.Tensor\n",
    "        DoubleTensor = torch.cuda.DoubleTensor if x.is_cuda else torch.DoubleTensor\n",
    "\n",
    "        prediction = x.view(nB, nA, self.bbox_attrs, nG, nG).permute(0, 1, 3, 4, 2).contiguous()\n",
    "\n",
    "        # Get outputs\n",
    "        x = torch.sigmoid(prediction[..., 0])  # Center x\n",
    "        y = torch.sigmoid(prediction[..., 1])  # Center y\n",
    "        w = prediction[..., 2]  # Width\n",
    "        h = prediction[..., 3]  # Height\n",
    "        pred_conf = torch.sigmoid(prediction[..., 4])  # Conf\n",
    "        pred_cls = torch.sigmoid(prediction[..., 5:])  # Cls pred.\n",
    "\n",
    "        # Calculate offsets for each grid\n",
    "        grid_x = torch.arange(nG).repeat(nG, 1).view([1, 1, nG, nG]).type(FloatTensor)\n",
    "        grid_y = torch.arange(nG).repeat(nG, 1).t().view([1, 1, nG, nG]).type(FloatTensor)\n",
    "#          scaled_anchors = FloatTensor([(a_w / stride, a_h / stride) for a_w, a_h in self.anchors])\n",
    "        scaled_anchors = torch.div(self.anchors_tensor, stride)\n",
    "        anchor_w = scaled_anchors[:, 0:1].view((1, nA, 1, 1))\n",
    "        anchor_h = scaled_anchors[:, 1:2].view((1, nA, 1, 1))\n",
    "\n",
    "        # Add offset and scale with anchors\n",
    "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
    "        pred_boxes[..., 0] = x.data + grid_x\n",
    "        pred_boxes[..., 1] = y.data + grid_y\n",
    "        pred_boxes[..., 2] = torch.exp(w.data) * anchor_w\n",
    "        pred_boxes[..., 3] = torch.exp(h.data) * anchor_h\n",
    "\n",
    "        # Training\n",
    "        if targets is not None:\n",
    "\n",
    "            if x.is_cuda:\n",
    "                self.mse_loss = self.mse_loss.cuda()\n",
    "                self.bce_loss = self.bce_loss.cuda()\n",
    "                self.ce_loss = self.ce_loss.cuda()\n",
    "\n",
    "            nGT, nCorrect, mask, conf_mask, tx, ty, tw, th, tconf, tcls = build_targets(\n",
    "                pred_boxes=pred_boxes.cpu().data,\n",
    "                pred_conf=pred_conf.cpu().data,\n",
    "                pred_cls=pred_cls.cpu().data,\n",
    "                target=targets.cpu().data,\n",
    "                anchors=scaled_anchors.cpu().data,\n",
    "                num_anchors=nA,\n",
    "                num_classes=self.num_classes,\n",
    "                grid_size=nG,\n",
    "                ignore_thres=self.ignore_thres,\n",
    "                img_dim=self.image_dim,\n",
    "            )\n",
    "\n",
    "            nProposals = int((pred_conf > 0.5).sum().item())\n",
    "            recall = float(nCorrect / nGT) if nGT else 1\n",
    "            precision = float(nCorrect / nProposals) if nProposals !=0 else float(0)\n",
    "\n",
    "            # Handle masks\n",
    "            mask = Variable(mask.type(ByteTensor))\n",
    "            conf_mask = Variable(conf_mask.type(ByteTensor))\n",
    "\n",
    "            # Handle target variables\n",
    "            tx = Variable(tx.type(FloatTensor), requires_grad=False)\n",
    "            ty = Variable(ty.type(FloatTensor), requires_grad=False)\n",
    "            tw = Variable(tw.type(FloatTensor), requires_grad=False)\n",
    "            th = Variable(th.type(FloatTensor), requires_grad=False)\n",
    "            tconf = Variable(tconf.type(FloatTensor), requires_grad=False)\n",
    "            tcls = Variable(tcls.type(FloatTensor), requires_grad=False)\n",
    "\n",
    "            # Get conf mask where gt and where there is no gt\n",
    "            conf_mask_true = mask\n",
    "            conf_mask_false = conf_mask - mask\n",
    "\n",
    "            # Mask outputs to ignore non-existing objects\n",
    "            loss_x = self.mse_loss(x[mask], tx[mask])\n",
    "            loss_y = self.mse_loss(y[mask], ty[mask])\n",
    "            loss_w = self.mse_loss(w[mask], tw[mask])\n",
    "            loss_h = self.mse_loss(h[mask], th[mask])\n",
    "            loss_conf = self.bce_loss(pred_conf[conf_mask_false], tconf[conf_mask_false]) + self.bce_loss(\n",
    "                pred_conf[conf_mask_true], tconf[conf_mask_true]\n",
    "            )\n",
    "            loss_cls = (1 / nB) * self.ce_loss(pred_cls[mask], torch.argmax(tcls[mask], 1))\n",
    "            loss = loss_x + loss_y + loss_w + loss_h + loss_conf + loss_cls\n",
    "\n",
    "            return (\n",
    "                loss,\n",
    "                loss_x.item(),\n",
    "                loss_y.item(),\n",
    "                loss_w.item(),\n",
    "                loss_h.item(),\n",
    "                loss_conf.item(),\n",
    "                loss_cls.item(),\n",
    "                recall,\n",
    "                precision,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # If not in training phase return predictions\n",
    "            output = torch.cat(\n",
    "                (\n",
    "                    pred_boxes.view(nB, -1, 4) * stride,\n",
    "                    pred_conf.view(nB, -1, 1),\n",
    "                    pred_cls.view(nB, -1, self.num_classes),\n",
    "                ),\n",
    "                -1,\n",
    "            )\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88dfeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
    "    \"\"\"\n",
    "    Returns the IoU of two bounding boxes\n",
    "    \"\"\"\n",
    "    if not x1y1x2y2:\n",
    "        # Transform from center and width to exact coordinates\n",
    "        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "    else:\n",
    "        # Get the coordinates of bounding boxes\n",
    "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "\n",
    "    # get the corrdinates of the intersection rectangle\n",
    "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "    # Intersection area\n",
    "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(\n",
    "        inter_rect_y2 - inter_rect_y1 + 1, min=0\n",
    "    )\n",
    "    # Union Area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "    iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def non_max_suppression(prediction, num_classes, conf_thres=0.5, nms_thres=0.4):\n",
    "    \"\"\"\n",
    "    Removes detections with lower object confidence score than 'conf_thres' and performs\n",
    "    Non-Maximum Suppression to further filter detections.\n",
    "    Returns detections with shape:\n",
    "        (x1, y1, x2, y2, object_conf, class_score, class_pred)\n",
    "    \"\"\"\n",
    "\n",
    "    # From (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "    box_corner = prediction.new(prediction.shape)\n",
    "    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n",
    "    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n",
    "    prediction[:, :, :4] = box_corner[:, :, :4]\n",
    "\n",
    "    output = [None for _ in range(len(prediction))]\n",
    "    for image_i, image_pred in enumerate(prediction):\n",
    "        # Filter out confidence scores below threshold\n",
    "        conf_mask = (image_pred[:, 4] >= conf_thres).squeeze()\n",
    "        image_pred = image_pred[conf_mask]\n",
    "        # If none are remaining => process next image\n",
    "        if not image_pred.size(0):\n",
    "            continue\n",
    "        # Get score and class with highest confidence\n",
    "        class_conf, class_pred = torch.max(image_pred[:, 5 : 5 + num_classes], 1, keepdim=True)\n",
    "        # Detections ordered as (x1, y1, x2, y2, obj_conf, class_conf, class_pred)\n",
    "        detections = torch.cat((image_pred[:, :5], class_conf.float(), class_pred.float()), 1)\n",
    "        # Iterate through all predicted classes\n",
    "        unique_labels = detections[:, -1].cpu().unique()\n",
    "        if prediction.is_cuda:\n",
    "            unique_labels = unique_labels.cuda()\n",
    "        for c in unique_labels:\n",
    "            # Get the detections with the particular class\n",
    "            detections_class = detections[detections[:, -1] == c]\n",
    "            # Sort the detections by maximum objectness confidence\n",
    "            _, conf_sort_index = torch.sort(detections_class[:, 4], descending=True)\n",
    "            detections_class = detections_class[conf_sort_index]\n",
    "            # Perform non-maximum suppression\n",
    "            max_detections = []\n",
    "            while detections_class.size(0):\n",
    "                # Get detection with highest confidence and save as max detection\n",
    "                max_detections.append(detections_class[0].unsqueeze(0))\n",
    "                # Stop if we're at the last detection\n",
    "                if len(detections_class) == 1:\n",
    "                    break\n",
    "                # Get the IOUs for all boxes with lower confidence\n",
    "                ious = bbox_iou(max_detections[-1], detections_class[1:])\n",
    "                # Remove detections with IoU >= NMS threshold\n",
    "                detections_class = detections_class[1:][ious < nms_thres]\n",
    "\n",
    "            max_detections = torch.cat(max_detections).data\n",
    "            # Add max detections to outputs\n",
    "            output[image_i] = (\n",
    "                max_detections if output[image_i] is None else torch.cat((output[image_i], max_detections))\n",
    "            )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50a93a",
   "metadata": {},
   "source": [
    "### 4.  Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd9ede14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: NetworkDPU,\n",
    "               data_loader: EvalLoader,\n",
    "               conf_thres:int = 0.5,\n",
    "               nms_thres: int = 0.4\n",
    "               ) -> Tuple[float, float]:\n",
    "\n",
    "    print(f\"Running on platform: {platform.platform()}, \"\n",
    "          f\"machine: {platform.machine()}, \"\n",
    "          f\"python_version: {platform.python_version()}, \"\n",
    "          f\"processor: {platform.processor()}, \"\n",
    "          f\"system: {platform.system()}, \"\n",
    "          )\n",
    "\n",
    "    num_classes = 4\n",
    "    img_size = 416\n",
    "    iou_thres = 0.5\n",
    "\n",
    "    all_detections = []\n",
    "    all_annotations = []\n",
    "    \n",
    "    yoloL = YOLOLayer([(116, 90), (156, 198), (373, 326)], num_classes, img_size)\n",
    "    yoloM = YOLOLayer([(30, 61), (62, 45), (59, 119)], num_classes, img_size)\n",
    "    yoloS = YOLOLayer([(10, 13), (16, 30), (33, 23)], num_classes, img_size)    \n",
    "\n",
    "    for _, (imgs, targets) in enumerate(tqdm.tqdm(data_loader, desc=\"Detecting objects\")):\n",
    "\n",
    "        imgs = np.transpose(imgs, (0, 3, 2, 1)) # transposed input/outputs of model\n",
    "        o1, o2, o3 = model(imgs)\n",
    "        o1 = np.transpose(o1, (0, 3, 2, 1))\n",
    "        o2 = np.transpose(o2, (0, 3, 2, 1))\n",
    "        o3 = np.transpose(o3, (0, 3, 2, 1))\n",
    "        output = []\n",
    "        y1 = yoloS(o1)\n",
    "        y2 = yoloM(o3)\n",
    "        y3 = yoloL(o2)\n",
    "        output.append(y1)\n",
    "        output.append(y2)\n",
    "        output.append(y3)\n",
    "        outputs = torch.cat(output, 1)\n",
    "        outputs = non_max_suppression(outputs, 4, conf_thres=conf_thres, nms_thres=nms_thres)\n",
    "\n",
    "        for output, annotations in zip(outputs, targets):\n",
    "            annotations = torch.from_numpy(annotations)\n",
    "\n",
    "            all_detections.append([np.array([]) for _ in range(num_classes)])\n",
    "            if output is not None:\n",
    "                # Get predicted boxes, confidence scores and labels\n",
    "                pred_boxes = output[:, :5].cpu().numpy()\n",
    "                scores = output[:, 4].cpu().numpy()\n",
    "                pred_labels = output[:, -1].cpu().numpy()\n",
    "\n",
    "                # Order by confidence\n",
    "                sort_i = np.argsort(scores)\n",
    "                pred_labels = pred_labels[sort_i]\n",
    "                pred_boxes = pred_boxes[sort_i]\n",
    "\n",
    "                for label in range(num_classes):\n",
    "                    all_detections[-1][label] = pred_boxes[pred_labels == label]\n",
    "\n",
    "            all_annotations.append([np.array([]) for _ in range(num_classes)])\n",
    "            if any(annotations[:, -1] > 0):\n",
    "\n",
    "                annotation_labels = annotations[annotations[:, -1] > 0, 0].cpu().numpy()\n",
    "                _annotation_boxes = annotations[annotations[:, -1] > 0, 1:].cpu()\n",
    "\n",
    "                # Reformat to x1, y1, x2, y2 and rescale to image dimensions\n",
    "                annotation_boxes = np.empty_like(_annotation_boxes)\n",
    "                annotation_boxes[:, 0] = _annotation_boxes[:, 0] - _annotation_boxes[:, 2] / 2\n",
    "                annotation_boxes[:, 1] = _annotation_boxes[:, 1] - _annotation_boxes[:, 3] / 2\n",
    "                annotation_boxes[:, 2] = _annotation_boxes[:, 0] + _annotation_boxes[:, 2] / 2\n",
    "                annotation_boxes[:, 3] = _annotation_boxes[:, 1] + _annotation_boxes[:, 3] / 2\n",
    "                annotation_boxes *= img_size\n",
    "\n",
    "                for label in range(num_classes):\n",
    "                    all_annotations[-1][label] = annotation_boxes[annotation_labels == label, :]\n",
    "\n",
    "    average_precisions = {}\n",
    "    for label in range(num_classes):\n",
    "        true_positives = []\n",
    "        scores = []\n",
    "        num_annotations = 0\n",
    "\n",
    "        for i in tqdm.tqdm(range(len(all_annotations)), desc=f\"Computing AP for class '{label}'\"):\n",
    "            detections = all_detections[i][label]\n",
    "            annotations = all_annotations[i][label]\n",
    "\n",
    "            num_annotations += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            for *bbox, score in detections:\n",
    "                scores.append(score)\n",
    "\n",
    "                if annotations.shape[0] == 0:\n",
    "                    true_positives.append(0)\n",
    "                    continue\n",
    "\n",
    "                overlaps = bbox_iou_numpy(np.expand_dims(bbox, axis=0), annotations)\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap = overlaps[0, assigned_annotation]\n",
    "\n",
    "                if max_overlap >= iou_thres and assigned_annotation not in detected_annotations:\n",
    "                    true_positives.append(1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    true_positives.append(0)\n",
    "\n",
    "        # no annotations -> AP for this class is 0\n",
    "        if num_annotations == 0:\n",
    "            average_precisions[label] = 0\n",
    "            continue\n",
    "\n",
    "        true_positives = np.array(true_positives)\n",
    "        false_positives = np.ones_like(true_positives) - true_positives\n",
    "        # sort by score\n",
    "        indices = np.argsort(-np.array(scores))\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives = true_positives[indices]\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision = compute_ap(recall, precision)\n",
    "        average_precisions[label] = average_precision\n",
    "\n",
    "    logger = {}\n",
    "    print(\"Average Precisions:\")\n",
    "    for c, ap in average_precisions.items():\n",
    "        print(f\"+ Class '{c}' - AP: {ap}\")\n",
    "        logger[c] = ap\n",
    "\n",
    "    mAP = np.mean(list(average_precisions.values()))\n",
    "    logger[\"mAP\"] = mAP\n",
    "    print(f\"mAP: {mAP}\")\n",
    "\n",
    "    return logger, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb872f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluation(net, loader, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93816e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.1, 0.7, 0.1)\n",
    "y = np.arange(0.1, 0.7, 0.1)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "data = np.zeros((X.shape[0], Y.shape[1]))\n",
    "\n",
    "for conf, nms in zip(X.ravel(), Y.ravel()):\n",
    "    i = int(conf * 10 - 1)\n",
    "    j = int(nms * 10 - 1)\n",
    "    print(\"Conf:\", conf, \"NMS:\", nms)\n",
    "    _, mAP = evaluation(net, loader, conf, nms)\n",
    "    data[i, j] = mAP\n",
    "\n",
    "with open('mAP_tests.json', 'w') as f:\n",
    "    json.dump(data.tolist(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
